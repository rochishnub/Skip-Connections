{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torchvision.datasets import CIFAR10, MNIST\r\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multi-Layer Perceptron\r\n",
    "We used a simple fully connected MLP to compare the results of with skip-connected networks. Each network consists of an input layer, an output layer and list of hidden layers. The layers have a uniform number of neurons per layer.\r\n",
    "\r\n",
    "Each different network model has the following common input arguments:\r\n",
    "- *in_dim*: Dimensions of input vector (28x28 for MNIST, 32x32 for CIFAR-10)\r\n",
    "- *out_dim*: Dimensions of final output vector/number of classes (10 for MNIST, CIFAR-10)\r\n",
    "- *n_layers*: Number of hidden layers, default=18. Total layers is 2 more\r\n",
    "- *n_nodes*: Number of neurons in each layer, default=100"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Skip Connections\r\n",
    "Skip connections are extra connections between layers that is used to feed the output of one layer to the input of next layers skipping layers in between. Skip connections were introduced to solve degradation problems and enhance feature reusability. There are three widely-used variants: ResNet, DenseNet and UNet. We have implemented ResNet and DenseNet on an MLP model below.\r\n",
    "\r\n",
    "Further, for each variant, we construct 3 different architectures:\r\n",
    "- OneSkip: We skip one intermediate layer for each layer in the network\r\n",
    "- SourceSkip: We connect the input layer (or first hidden layer) to each layer in the network\r\n",
    "- FullSkip: Each layer is fully connected to every other layer by skips.\r\n",
    "\r\n",
    "### ResNets\r\n",
    "Residual Nets (ResNet) follow the principle of having residual blocks where the the skipped input is vectorially added to the next layer. In our implementation, each layer depicts a residual block. The number of features in the hidden layers are kept uniform to make addition of vectors easier.\r\n",
    "\r\n",
    "### DenseNets\r\n",
    "In DenseNets, the output of a layer is concatenated with the input to the next layer. Thus the input dimensions increase along the network for DenseNets, whereas for ResNets they remain the same. Due to concatenations the features of previous layers are carried on to the next layers. Our implementation is similar to ResNet."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class MLP(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, n_layers=3, n_nodes=100):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.in_layer = nn.Linear(in_dim, n_nodes)\r\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(n_nodes, n_nodes) for i in range(n_layers)])\r\n",
    "        self.out_layer = nn.Linear(n_nodes, out_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.shape[0]\r\n",
    "        x = x.view(batch_size, -1)\r\n",
    "        \r\n",
    "        x = F.relu(self.in_layer(x))\r\n",
    "        for i,apply_layer in enumerate(self.hidden_layers):\r\n",
    "            x = F.relu(apply_layer(x))\r\n",
    "        y_pred = self.out_layer(x)\r\n",
    "        return y_pred,1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "class OneSkipDN(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, n_layers=3, n_nodes=100):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.in_layer = nn.Linear(in_dim, n_nodes)\r\n",
    "        self.next_layer = nn.Linear(in_dim+n_nodes, n_nodes)\r\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(2*n_nodes, n_nodes) for i in range(n_layers-1)])\r\n",
    "        self.out_layer = nn.Linear(2*n_nodes, out_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.shape[0]\r\n",
    "        x = x.view(batch_size, -1)\r\n",
    "\r\n",
    "        out_skip = F.relu(self.in_layer(x))\r\n",
    "        out_dir = F.relu(self.next_layer(torch.cat((x,out_skip), 1)))\r\n",
    "\r\n",
    "        for _,apply_layer in enumerate(self.hidden_layers):\r\n",
    "            out_temp = out_skip\r\n",
    "            out_skip = out_dir\r\n",
    "            out_dir = F.relu(apply_layer(torch.cat((out_skip, out_temp), 1)))\r\n",
    "        \r\n",
    "        y_pred = self.out_layer(torch.cat((out_skip, out_dir), 1))\r\n",
    "        return y_pred,1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "class SourceSkipDN(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, n_layers=3, n_nodes=100):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.in_layer = nn.Linear(in_dim, n_nodes)\r\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(in_dim+n_nodes, n_nodes) for i in range(n_layers)])\r\n",
    "        self.out_layer = nn.Linear(in_dim+n_nodes, out_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.shape[0]\r\n",
    "        x = x.view(batch_size, -1)\r\n",
    "\r\n",
    "        out_dir = F.relu(self.in_layer(x))\r\n",
    "        for _,apply_layer in enumerate(self.hidden_layers):\r\n",
    "            out_dir = F.relu(apply_layer(torch.cat((out_dir, x), 1)))\r\n",
    "        y_pred = self.out_layer(torch.cat((out_dir, x), 1))\r\n",
    "        return y_pred,1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "class FullSkipDN(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, n_layers=3, n_nodes=100):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.in_layer = nn.Linear(in_dim, n_nodes)\r\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(in_dim+(i*n_nodes), n_nodes) for i in range(1,n_layers+1)])\r\n",
    "        self.out_layer = nn.Linear(in_dim+((n_layers+1)*n_nodes), out_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.shape[0]\r\n",
    "        x = x.view(batch_size, -1)\r\n",
    "\r\n",
    "        out_skips = [x]\r\n",
    "        out_skips.append(F.relu(self.in_layer(x)))\r\n",
    "\r\n",
    "        for _,apply_layer in enumerate(self.hidden_layers):\r\n",
    "            nxt_out = F.relu(apply_layer(torch.cat(out_skips, 1)))\r\n",
    "            out_skips.append(nxt_out)\r\n",
    "        y_pred = self.out_layer(torch.cat(out_skips, 1))\r\n",
    "        return y_pred,1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class OneSkipRN(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, n_layers=3, n_nodes=100):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.in_layer = nn.Linear(in_dim, n_nodes)\r\n",
    "        self.next_layer = nn.Linear(n_nodes, n_nodes)\r\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(n_nodes, n_nodes) for i in range(n_layers-1)])\r\n",
    "        self.out_layer = nn.Linear(n_nodes, out_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.shape[0]\r\n",
    "        x = x.view(batch_size, -1)\r\n",
    "\r\n",
    "        out_skip = F.relu(self.in_layer(x))\r\n",
    "        out_dir = F.relu(self.next_layer(out_skip))\r\n",
    "\r\n",
    "        for _,apply_layer in enumerate(self.hidden_layers):\r\n",
    "            out_temp = out_skip\r\n",
    "            out_skip = out_dir\r\n",
    "            out_dir = F.relu(apply_layer(out_temp+out_skip))\r\n",
    "        \r\n",
    "        y_pred = self.out_layer(out_skip+out_dir)\r\n",
    "        return y_pred,1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class SourceSkipRN(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, n_layers=3, n_nodes=100):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.in_layer = nn.Linear(in_dim, n_nodes)\r\n",
    "        self.next_layer = nn.Linear(n_nodes, n_nodes)\r\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(n_nodes, n_nodes) for i in range(n_layers-1)])\r\n",
    "        self.out_layer = nn.Linear(n_nodes, out_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.shape[0]\r\n",
    "        x = x.view(batch_size, -1)\r\n",
    "\r\n",
    "        out_skip = F.relu(self.in_layer(x))\r\n",
    "        out_dir = F.relu(self.next_layer(out_skip))\r\n",
    "\r\n",
    "        for _,apply_layer in enumerate(self.hidden_layers):\r\n",
    "            out_dir = F.relu(apply_layer(out_dir+out_skip))\r\n",
    "        \r\n",
    "        y_pred = self.out_layer(out_skip+out_dir)\r\n",
    "        return y_pred,1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "class FullSkipRN(nn.Module):\r\n",
    "    def __init__(self, in_dim, out_dim, n_layers=3, n_nodes=100):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.in_layer = nn.Linear(in_dim, n_nodes)\r\n",
    "        self.next_layer = nn.Linear(n_nodes, n_nodes)\r\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(n_nodes, n_nodes) for i in range(n_layers-1)])\r\n",
    "        self.out_layer = nn.Linear(n_nodes, out_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.shape[0]\r\n",
    "        x = x.view(batch_size, -1)\r\n",
    "\r\n",
    "        x = F.relu(self.in_layer(x))\r\n",
    "        out_skips = [x]\r\n",
    "        out_skips.append(F.relu(self.next_layer(x)))\r\n",
    "\r\n",
    "        for _,apply_layer in enumerate(self.hidden_layers):\r\n",
    "            nxt_out = F.relu(apply_layer(sum(out_skips)))\r\n",
    "            out_skips.append(nxt_out)\r\n",
    "        \r\n",
    "        y_pred = self.out_layer(sum(out_skips))\r\n",
    "        return y_pred,1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "a = torch.randn(1,3)\r\n",
    "b = torch.randn(1,3)\r\n",
    "a,b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-0.5225,  0.1325, -1.3603]]), tensor([[0.3897, 0.4429, 1.6402]]))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "arr = [a,b]\r\n",
    "sum(arr)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1328,  0.5753,  0.2799]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "torch.cat(arr,1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.5225,  0.1325, -1.3603,  0.3897,  0.4429,  1.6402]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "65636d361fc736ae0b1f9eeae3216986d5f42230c906e5696168f8f628d1ae28"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}